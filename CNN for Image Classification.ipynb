{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4097,
     "status": "ok",
     "timestamp": 1727869696217,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1727869699295,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "FIleuCAjoFD8",
    "outputId": "9c409700-4a44-4ac5-b45a-374e448511a6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1727869709542,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "0koUcJMJpEBD",
    "outputId": "12d2b27d-22f4-4af3-833f-5ca0cd00336c"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(training_dir, testing_dir):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        testing_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    return train_generator, test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1727869749266,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "SH4WzfOhpKc3",
    "outputId": "eefdf71b-6707-4ad0-99db-04603d820197"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1727869817668,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional Layer\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Adding another convolutional layer\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compiling the CNN\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1727869820333,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "XPzPrMckl-hV",
    "outputId": "329e2f0a-ec6c-4b72-c6ad-000f7ba7cda6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1727869823557,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1727869826266,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1727869828932,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1727869831487,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1727870028191,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1727870049309,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, test_generator, epochs=25):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=len(test_generator)\n",
    "    )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53294,
     "status": "ok",
     "timestamp": 1727870127564,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "XUj1W4PJptta",
    "outputId": "6af733bf-672f-4229-efe2-f0847b4118e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1727870175470,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "gsSiWEJY1BPB",
    "outputId": "3a1eabe0-aa2b-48ac-cc6e-a32906dbf08e"
   },
   "outputs": [],
   "source": [
    "def predict_image(model, img_path):\n",
    "    test_image = image.load_img(img_path, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = model.predict(test_image)\n",
    "\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'dog'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1727870200094,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ED9KB3I54c1i",
    "outputId": "7f130fcb-f755-463d-c743-b9d3565b5e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 133ms/step - accuracy: 0.5309 - loss: 0.7173 - val_accuracy: 0.6720 - val_loss: 0.6477\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 196ms/step - accuracy: 0.6128 - loss: 0.6542 - val_accuracy: 0.6925 - val_loss: 0.5914\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 195ms/step - accuracy: 0.6776 - loss: 0.6026 - val_accuracy: 0.6995 - val_loss: 0.5842\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 195ms/step - accuracy: 0.6958 - loss: 0.5855 - val_accuracy: 0.7325 - val_loss: 0.5523\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 197ms/step - accuracy: 0.7162 - loss: 0.5664 - val_accuracy: 0.7555 - val_loss: 0.5145\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 196ms/step - accuracy: 0.7242 - loss: 0.5494 - val_accuracy: 0.7130 - val_loss: 0.5513\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 201ms/step - accuracy: 0.7384 - loss: 0.5282 - val_accuracy: 0.7435 - val_loss: 0.5231\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 197ms/step - accuracy: 0.7526 - loss: 0.5076 - val_accuracy: 0.7730 - val_loss: 0.4968\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 17/25\n",
      "\u001b[1m  1/250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 169ms/step - accuracy: 0.7812 - loss: 0.4401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 09:34:16.863894: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 221ms/step - accuracy: 0.7469 - loss: 0.5198 - val_accuracy: 0.7790 - val_loss: 0.4820\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 232ms/step - accuracy: 0.7613 - loss: 0.5122 - val_accuracy: 0.7675 - val_loss: 0.4769\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 196ms/step - accuracy: 0.7753 - loss: 0.4754 - val_accuracy: 0.7790 - val_loss: 0.4690\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 199ms/step - accuracy: 0.7705 - loss: 0.4818 - val_accuracy: 0.7865 - val_loss: 0.4612\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 199ms/step - accuracy: 0.7739 - loss: 0.4829 - val_accuracy: 0.7820 - val_loss: 0.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "The image cat_or_dog_1.jpg is a dog.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "The image cat_or_dog_2.jpg is a cat.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Specify directories\n",
    "    training_dir = \"/Users/wangpeter/Downloads/Project - CNN for Image Classification/dataset/training_set\"\n",
    "    testing_dir = \"/Users/wangpeter/Downloads/Project - CNN for Image Classification/dataset/test_set\"\n",
    "    single_prediction_dir = \"/Users/wangpeter/Downloads/Project - CNN for Image Classification/dataset/single_prediction\"\n",
    "\n",
    "    # Preprocess data\n",
    "    train_generator, test_generator = preprocess_data(training_dir, testing_dir)\n",
    "\n",
    "    # Build and train the model\n",
    "    cnn_model = build_cnn()\n",
    "    train_model(cnn_model, train_generator, test_generator, epochs=25)\n",
    "\n",
    "    # Save the trained model\n",
    "    cnn_model.save(\"cat_dog_classifier.h5\")\n",
    "\n",
    "    # Load images from the single_prediction folder and classify\n",
    "    for img_file in os.listdir(single_prediction_dir):\n",
    "        img_path = os.path.join(single_prediction_dir, img_file)\n",
    "        prediction = predict_image(cnn_model, img_path)\n",
    "        print(f\"The image {img_file} is a {prediction}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2fBThgo8wJQn6Xf6V6crC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
